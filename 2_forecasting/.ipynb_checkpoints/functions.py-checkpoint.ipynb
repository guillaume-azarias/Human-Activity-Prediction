{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script centralized the functions used in the notebook Prophet Caru\n",
    "\n",
    "The goal of Prophet Caru is to activity patterns using Facebook Prophet. See link to the [original tutorial](https://medium.com/analytics-vidhya/time-series-forecast-anomaly-detection-with-facebook-prophet-558136be4b8d).\n",
    "\n",
    "The functions in this script are:\n",
    "* **df_dev_formater**: Load a csv file containing the data from a single device and return a pandas dataframe where the date and time column is formatted in datetime for Switzerland.\n",
    "* **find_index**: Find the index of a date and time for a specific dataframe. Can be helpful for data exploration.  \n",
    "* **df_generator**: Prepare the dataframe according to be processed by Prophet. Critical function of Prophet Caru: please read the description within the function definition.\n",
    "* **prophet_fit**: Fit the model to the time-series data and generate forecast for specified time frames. Version of the tutorial modified to work with shorter time frame than entire days (main limitation of the tutorial).\n",
    "* **prophet_plot**: Plot actual, predictions, and anomalous values. Writing of the label for anomalies were disabled. Version of the tutorial modified to work with shorter time frame than entire days.\n",
    "* **get_outliers**: Combine the actual values and forecast in a data frame and identify the outliers. From the tutorial.\n",
    "* **execute_cross_validation_and_performance_loop**: Execute Cross Validation and Performance Loop. This function is taken from this [article](https://medium.com/@jeanphilippemallette/prophet-auto-selection-with-cross-validation-7ba2c0a3beef) from Jean-Philippe Mallette.\n",
    "\n",
    "---------------\n",
    "### *Note: This script should be located in the same folder as Prophet Caru.ipynb*\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fbprophet\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbprophet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_dev_formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dev_formater(device_nb):\n",
    "    \"\"\"\n",
    "    This is a script to load a csv file created by df_dev_generator.\n",
    "    It loads a csv file, drop the 'Unnamed: 0' column and convert the\n",
    "    ts_date column (object) into a column named ds and formated in \n",
    "    local Swiss time (datetime).\n",
    "    \n",
    "    Arg:\n",
    "        - device_nb: String. 2 digit number of the device\n",
    "    \n",
    "    Returns:\n",
    "        - df_dev: dataframe to pass to df_generator\n",
    "    \"\"\"\n",
    "    # Data Loading\n",
    "    file_name = '../Data/interim/device' + str(device_nb) + '_alldays.csv'\n",
    "\n",
    "    df_raw = pd.read_csv(file_name, delimiter=',')\n",
    " \n",
    "    # Clean the dataset\n",
    "    df_raw = df_raw.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "    # Convert ts_date into a datetime and convert UTC into Swiss Time\n",
    "    utc_time = pd.to_datetime(df_raw['ts_date'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "    df_raw['local_time_to_drop'] = utc_time.apply(lambda x: x.tz_convert('Europe/Zurich'))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_raw['ts_date'] = df_raw['local_time_to_drop']\n",
    "    df_raw.rename({'ts_date': 'ds'}, axis=1, inplace=True)\n",
    "    df_dev = df_raw.drop(['local_time_to_drop'],axis=1)\n",
    "    \n",
    "    # Make sure that only the relevant device is included in df_dev\n",
    "    device = df_dev['device'].unique()\n",
    "\n",
    "    return device, df_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(dataframe, date, starting_time=None):\n",
    "    \"\"\"\n",
    "    This function allows to find the index for a specific dataframe, date and time.\n",
    "    \n",
    "    Args:\n",
    "        - dataframe: pandas dataframe of interest\n",
    "        - date: string formatted as '2019-04-08'\n",
    "        - time: string formatted as '20:30'. If None, time = '0:00'.\n",
    "    \n",
    "    Print the index\n",
    "    \"\"\"\n",
    "    assert dataframe.shape[0]>0, 'The dataframe is empty !'\n",
    "    \n",
    "    if not starting_time:\n",
    "        starting_time = '0:00' # day time of the first day of the df. Might be relevant to get a full day and help the day/night clustering\n",
    "    \n",
    "    date_str = date + ' ' + starting_time\n",
    "    date_dt = datetime.strptime(date_str,'%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Apply the Swiss time zone. http://pytz.sourceforge.net/#localized-times-and-date-arithmetic\n",
    "    swiss = timezone('Europe/Zurich')\n",
    "    date_dt = swiss.localize(date_dt)\n",
    "\n",
    "    # Filter according to begin and end. Does not take in account the starting time...\n",
    "    date_on = dataframe[(dataframe['ds'] >= date_dt)]\n",
    "    index = date_on.shape[0]\n",
    "    \n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_generator(df_dev, device, parameter, begin, end, sampling_period_st,\n",
    "                 sampling_period_num, graph=None, predict_day=1):\n",
    "    \"\"\"\n",
    "    This function is generating a new dataframe from entire dataframe.\n",
    "    Note that for now, df_dev is the device 31 specific dataframe.\n",
    "    \n",
    "    Args:\n",
    "        - df_dev: Dataframe. Full dataframe with\n",
    "            o device                                object\n",
    "            o tenant                                object\n",
    "            o ds             datetime64[ns, Europe/Zurich]\n",
    "            o light                                float64\n",
    "            o temperature                          float64\n",
    "            o humidity                             float64\n",
    "            o co2                                  float64\n",
    "        - parameter: String. among 'light', 'temperature', 'humidity', 'co2'.\n",
    "          co2 might be themore \"human-activity\" related\n",
    "        - begin: String. Day of the beginning of the new dataframe.\n",
    "        - end: String. Day of the end of the new dataframe.\n",
    "        - sampling_period_st: String. Duration of bin for data downsampling. !\n",
    "          Format is not accurate for date calculations.\n",
    "        - sampling_period_num: Float. Number of hours of the sampling_period_st.\n",
    "          Example: resampling every 30min: '0.5\n",
    "        - graph=None: Set to None to show the graph and a value if you don't want\n",
    "          to show the graph.\n",
    "        - predict_day=1. Number of days predicted. 1 by default.\n",
    "    \n",
    "    Returns:\n",
    "        df: pandas dataframe for the specific parameter\n",
    "        predict_n = Int. Number of data points to predict.\n",
    "        today_index = df.shape[0] - predict_n # index\n",
    "        lookback_n = int(today_index*0.99) # 1 week 336\n",
    "        \n",
    "    Note: Real values of predict_n, today_index and lookback_n depend on\n",
    "          sampling_period_st and sampling_period_num. Wrong indications of\n",
    "          sampling_period_st or sampling_period_num can lead to wrong predictions.\n",
    "          \n",
    "    TODO: Check if any existing function converts sampling_period_st into \n",
    "          sampling_period_st and vice-versa. Use a Regex-based function could take\n",
    "          care of it and avoid miscalculations.\n",
    "    \"\"\"\n",
    "    # Saving name\n",
    "    name = str(device) + ': '+ str(parameter) + ' from the ' + str(begin) + ' until the ' + str(end)\n",
    "    \n",
    "    # Prepare the dates\n",
    "    starting_time = '21:00' # day time of the first day of the df. Might be relevant to get a full day and help the day/night clustering\n",
    "    \n",
    "    begin_str = begin + ' ' + starting_time\n",
    "    end_str = end + ' ' + starting_time\n",
    "\n",
    "    begin_dt = datetime.strptime(begin_str,'%Y-%m-%d %H:%M')\n",
    "    end_dt = datetime.strptime(end_str,'%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Apply the Swiss time zone. http://pytz.sourceforge.net/#localized-times-and-date-arithmetic\n",
    "    swiss = timezone('Europe/Zurich')\n",
    "    # swiss.zone\n",
    "    begin_dt = swiss.localize(begin_dt)\n",
    "    end_dt = swiss.localize(end_dt)\n",
    "    \n",
    "    # Sorry this is not elegant. Fix it\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    # Filter according to begin and end. Does not take in account the starting time...\n",
    "    df_full = df_dev[(df_dev['ds'] >= begin_dt) & (df_dev['ds'] <= end_dt)]\n",
    "    \n",
    "    # Generate a parameter-specific df\n",
    "    df_full.rename(columns={parameter: 'y'}, inplace=True)\n",
    "    df_parameter = df_full[['ds', 'y']]\n",
    "\n",
    "    # Set ds as the index\n",
    "    df_parameter.index = df_parameter.ds\n",
    "    df_parameter.reindex # TO DELETE IF IT CRASHES\n",
    "    df_original = df_parameter.copy()\n",
    "    \n",
    "    # Downsampling and fill NaN. Need to have set ds as the index.\n",
    "    df = df_parameter.resample(sampling_period_st).pad() # Disable the pad function to let Prophet deal with missing data\n",
    "#     df = df_parameter.resample(sampling_period) # '30T' --> 30min\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    if not graph:\n",
    "        # Plot the df\n",
    "        fig, ax = plt.subplots(figsize=(8,3))\n",
    "        df_original.y.plot(label=\"Original\", color='gray', linewidth=1) # Data with original frequency\n",
    "        df.y.plot(label=\"Resampled data\", color='black', marker='o', linestyle='dashed',linewidth=0.5, markersize=2) \n",
    "\n",
    "        myFmt = DateFormatter(\"%d/%m %H:%M\")\n",
    "        ax.xaxis.set_major_formatter(myFmt)\n",
    "        plt.xlabel('Time', fontsize=8)\n",
    "        plt.ylabel(parameter, fontsize=8)\n",
    "        plt.title(name, fontsize=14)\n",
    "        plt.legend(loc='upper right')\n",
    "        \n",
    "        # vertical lines\n",
    "        begin_str_vl = begin + ' 0:00'\n",
    "        end_str_vl = end + ' 0:00'\n",
    "\n",
    "        begin_dt_vl = datetime.strptime(begin_str_vl,'%Y-%m-%d %H:%M') + timedelta(days=1)\n",
    "        end_dt_vl = datetime.strptime(end_str_vl,'%Y-%m-%d %H:%M')\n",
    "        \n",
    "        begin_dt_vl = swiss.localize(begin_dt_vl)\n",
    "        end_dt_vl = swiss.localize(end_dt_vl)\n",
    "    \n",
    "        daterange = pd.date_range(begin_dt_vl, end_dt_vl)\n",
    "        for single_date in daterange:\n",
    "            plt.axvline(x=single_date, color='lightseagreen', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "#         # If you want to save the file\n",
    "#         folder = '/Users/guillaume/Documents/DS2020/Caru/caru/figures/'\n",
    "#         filename = folder + name + '.png'\n",
    "#         plt.savefig(filename, bbox_inches = \"tight\")\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "    # Shape report\n",
    "    last_df = df.shape[0]-1\n",
    "    last = df_dev.shape[0]-1\n",
    "#     bining_frequency = 30  # Integer. Sampling period in min. Example 30T --> 30.\n",
    "#     nb_of_days = int(df.shape[0]/((60/bining_frequency)*24))\n",
    "    print('Full dataset: {:%Y-%m-%d} to the {:%Y-%m-%d}. Analysed data the {:%Y-%m-%d} to the {:%Y-%m-%d}.'\n",
    "          .format(df_dev['ds'][0], df_dev['ds'][last], df['ds'][0], df['ds'][last_df]))\n",
    "#     print('Full dataset: {:%Y-%m-%d} to the {:%Y-%m-%d}. Analysed data the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'\n",
    "#           .format(df_dev['ds'][0], df_dev['ds'][last], df['ds'][0], df['ds'][last_df]), nb_of_days)\n",
    "    \n",
    "    # specify the time frames. Note: current binning is 30min\n",
    "    predict_n = int(predict_day*24/sampling_period_num) # in data points\n",
    "    today_index = df.shape[0] - predict_n # index\n",
    "    lookback_n = int(today_index*0.99) # 1 week 336\n",
    "    \n",
    "    return df, predict_n, today_index, lookback_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prophet_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code reference: https://github.com/paullo0106/prophet_anomaly_detection/blob/master/utils.py\n",
    "\n",
    "def prophet_fit(df, prophet_model, today_index, sampling_period_st, sampling_period_num, lookback_days=None, predict_days=21):\n",
    "    \"\"\"\n",
    "    Fit the model to the time-series data and generate forecast for specified time frames\n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    prophet_model : Prophet model\n",
    "        Prophet model with configured parameters\n",
    "    today_index : int\n",
    "        The index of the date list in the df dataframe, where Day (today_index-lookback_days)th\n",
    "        to Day (today_index-1)th is the time frame for training\n",
    "    sampling_period_st: string. Period of resampling.\n",
    "        Relevant parameter for make_future_dataframe. Example: resampling every 30min: '30T'\n",
    "    sampling_period_num: float. Number of hours of the sampling_period_st. Example: resampling every 30min: '0.5\n",
    "    lookback_days: int, optional (default=None)\n",
    "        As described above, use all the available dates until today_index as\n",
    "        training set if no value assigned\n",
    "    predict_days: int, optional (default=21)\n",
    "        Make prediction for Day (today_index)th to Day (today_index+predict_days)th\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib Figure\n",
    "        A plot with actual data, predicted values and the interval\n",
    "    forecast : pandas DataFrame\n",
    "        The predicted result in a format of dataframe\n",
    "    prophet_model : Prophet model\n",
    "        Trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # segment the time frames\n",
    "    lookback_days_show = int(lookback_days/(24/sampling_period_num))\n",
    "    predict_days_show = int(predict_days/(24/sampling_period_num))\n",
    "    \n",
    "    baseline_ts = df['ds'][:today_index]\n",
    "    baseline_y = df['y'][:today_index]\n",
    "    if not lookback_days:\n",
    "        print('o Trained on data from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][0],\n",
    "                                                            df['ds'][today_index - 1],\n",
    "                                                            lookback_days_show))\n",
    "    else:\n",
    "        baseline_ts = df['ds'][today_index - lookback_days:today_index]\n",
    "        baseline_y = df.y[today_index - lookback_days:today_index]\n",
    "        print('o Trained on the data from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][today_index - lookback_days],\n",
    "                                                            df['ds'][today_index - 1],\n",
    "                                                            lookback_days_show))\n",
    "    print('o Predict from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][today_index],\n",
    "                                              df['ds'][today_index + predict_days - 1],\n",
    "                                              predict_days_show))\n",
    "\n",
    "    # fit the model\n",
    "    prophet_model.fit(pd.DataFrame({'ds': baseline_ts.values,\n",
    "                                    'y': baseline_y.values}))\n",
    "    \n",
    "    # make prediction. Note that the frequency of the sampling period used for the dataframe\n",
    "    # To make a new frequency, check \n",
    "    # https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    future = prophet_model.make_future_dataframe(periods=predict_days, freq = sampling_period_st)\n",
    "#     future = prophet_model.make_future_dataframe(periods=predict_days, freq = '30T') \n",
    "    forecast = prophet_model.predict(future)\n",
    "    \n",
    "    # generate the plot\n",
    "    fig = prophet_model.plot(forecast)\n",
    "    return fig, forecast, prophet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prophet_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_plot(df, fig, today_index, lookback_days=None, predict_days=21, outliers=list()):\n",
    "    \"\"\"\n",
    "    Plot the actual, predictions, and anomalous values\n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    fig : matplotlib Figure\n",
    "        A plot with actual data, predicted values and the interval which we previously obtained\n",
    "        from Prophet's model.plot(forecast).\n",
    "    today_index : int\n",
    "        The index of the date list in the dataframe dividing the baseline and prediction time frames.\n",
    "    lookback_days : int, optional (default=None)\n",
    "        Day (today_index-lookback_days)th to Day (today_index-1)th is the baseline time frame for training.\n",
    "    predict_days : int, optional (default=21)\n",
    "        Make prediction for Day (today_index)th to Day (today_index+predict_days)th.\n",
    "    outliers : a list of (datetime, int) tuple\n",
    "        The outliers we want to highlight on the plot.\n",
    "    \"\"\"\n",
    "    # retrieve the subplot in the generated Prophets matplotlib figure\n",
    "    ax = fig.get_axes()[0]\n",
    "\n",
    "    start = 0\n",
    "#     end = today_index + predict_days # Original code\n",
    "    end = df.shape[0]\n",
    "    x_pydatetime = df['ds'].dt.to_pydatetime()\n",
    "    # highlight the actual values of the entire time frame\n",
    "    ax.plot(x_pydatetime[start:end],\n",
    "            df.y[start:end],\n",
    "            color='orange', label='Actual')\n",
    "\n",
    "    # plot each outlier in red dot and annotate the date\n",
    "    for outlier in outliers:\n",
    "        ax.scatter(outlier[0], outlier[1], s=16, color='red', label='Anomaly')\n",
    "#         ax.text(outlier[0], outlier[1], str(outlier[0])[:10], color='red', fontsize=6)\n",
    "\n",
    "    # highlight baseline time frame with gray background\n",
    "    if lookback_days:\n",
    "        start = today_index - lookback_days\n",
    "    ax.axvspan(x_pydatetime[start],\n",
    "               x_pydatetime[today_index],\n",
    "               color=sns.xkcd_rgb['grey'],\n",
    "               alpha=0.2)\n",
    "\n",
    "    # annotate the areas, and position the text at the bottom 5% by using ymin + (ymax - ymin) / 20\n",
    "    ymin, ymax = ax.get_ylim()[0], ax.get_ylim()[1]\n",
    "    ax.text(x_pydatetime[int((start + today_index) / 2)], ymin + (ymax - ymin) / 20, 'Baseline area')\n",
    "    ax.text(x_pydatetime[int((today_index * 2 + predict_days) / 2)], ymin + (ymax - ymin) / 20, 'Prediction area')\n",
    "\n",
    "    # re-organize the legend\n",
    "    patch1 = mpatches.Patch(color='red', label='Anomaly')\n",
    "    patch2 = mpatches.Patch(color='orange', label='Actual')\n",
    "    patch3 = mpatches.Patch(color='skyblue', label='Predict and interval')\n",
    "    patch4 = mpatches.Patch(color='grey', label='Baseline area')\n",
    "    plt.legend(handles=[patch1, patch2, patch3, patch4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(df, forecast, today_index, predict_days=21):\n",
    "    \"\"\"\n",
    "    Combine the actual values and forecast in a data frame and identify the outliers\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    forecast : pandas DataFrame\n",
    "        The predicted result in a dataframe which was previously generated by\n",
    "        Prophet's model.predict(future)\n",
    "    today_index : int\n",
    "        The summary statistics of the right tree node.\n",
    "    predict_days : int, optional (default=21)\n",
    "        The time frame we segment as prediction period\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outliers : a list of (datetime, int) tuple\n",
    "        A list of outliers, the date and the value for each\n",
    "    df_pred : pandas DataFrame\n",
    "        The data set contains actual and predictions for the forecast time frame\n",
    "    \"\"\"\n",
    "    df_pred = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(predict_days)\n",
    "    df_pred.index = df_pred['ds'].dt.to_pydatetime()\n",
    "    df_pred.columns = ['ds', 'preds', 'lower_y', 'upper_y']\n",
    "    df_pred['actual'] = df['y'][today_index: today_index + predict_days].values\n",
    "\n",
    "    # construct a list of outliers\n",
    "    outlier_index = list()\n",
    "    outliers = list()\n",
    "    for i in range(df_pred.shape[0]):\n",
    "        actual_value = df_pred['actual'][i]\n",
    "        if actual_value < df_pred['lower_y'][i] or actual_value > df_pred['upper_y'][i]:\n",
    "            outlier_index += [i]\n",
    "            outliers.append((df_pred.index[i], actual_value))\n",
    "            # optional, print out the evaluation for each outlier\n",
    "#             print('=====')\n",
    "#             print('actual value {} fall outside of the prediction interval'.format(actual_value))\n",
    "#             print('interval: {} to {}'.format(df_pred['lower_y'][i], df_pred['upper_y'][i]))\n",
    "#             print('Date: {}'.format(str(df_pred.index[i])[:10]))\n",
    "\n",
    "    return outliers, df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute_cross_validation_and_performance_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cross_validation_and_performance_loop(cross_valid_params, metric = 'mse'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Execute Cross Validation and Performance Loop\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    cross_valid_params: List of dict\n",
    "      dict value same as cross_validation function argument\n",
    "      model, horizon, period, initial\n",
    "    metric: string \n",
    "      sort the dataframe in ascending order base on the \n",
    "      performance metric of your choice either mse, rmse, mae or mape\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pd.DataFrame with cross_validation result. One row\n",
    "    per different configuration sorted ascending base on\n",
    "    the metric inputed by the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert metric in ['mse','rmse','mae','mape'], \\\n",
    "                    'metric must be either mse, rmse, mae or mape'\n",
    "\n",
    "    df_ps = pd.DataFrame()\n",
    "\n",
    "    for cross_valid_param in cross_valid_params:\n",
    "        df_cv = cross_validation(**cross_valid_param)\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        df_p['initial'] = cross_valid_param['initial']\n",
    "        df_p['period'] = cross_valid_param['period']\n",
    "        df_ps = df_ps.append(df_p)\n",
    "    \n",
    "    df_ps = df_ps[['initial','horizon','period','mse'\n",
    "                    ,'rmse','mae','mape','coverage']]\n",
    "    return df_ps.sort_values(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
