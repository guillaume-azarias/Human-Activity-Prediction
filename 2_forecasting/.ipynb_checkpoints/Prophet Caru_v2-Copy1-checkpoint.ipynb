{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/paullo0106/prophet_anomaly_detection/blob/master/prophet_anomaly_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdO5x8DMJrmm"
   },
   "source": [
    "# Anomaly detection using Facebook Prophet:\n",
    "\n",
    "see [link to the tutorial](https://anomaly.io/anomaly-detection-clustering/index.html) or here: /Users/guillaume/Documents/DS2020/Caru/Documents/Anomaly detection with Facebook Prophet.pdf\n",
    "\n",
    "This is a script to:\n",
    "* Discover and diagnose the patterns easily through visualization and having anomalous values flagged in the pyplot\n",
    "* Experiment quickly with different time windows and model parameters such as confidence interval and make adjustments\n",
    "\n",
    "We define pattern as a **transient**, reversible and significant change in one or several physical parameter(s).\n",
    "Examples of patterns:\n",
    "* Someone goes to bed (CO2 decreases/increases and stay stable)\n",
    "* Someone wakes up in the morning\n",
    "* Someone wakes up nightly for a bathroom breaks\n",
    "* Unknown activities that nevertheless occur regularly\n",
    "\n",
    "Strategy:\n",
    "* Prediction of general trend using facebook using smoothed data\n",
    "* Identification significant deviation from prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqBSZowXa-O0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8FSgHwCa6bi"
   },
   "outputs": [],
   "source": [
    "import fbprophet\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rKZsaWFTa9Km",
    "outputId": "15c0d68c-89da-4503-b0c4-98703d9a789a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbprophet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to put in a helper file (don't know yet how to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dev_formater(device_nb):\n",
    "    \"\"\"\n",
    "    This is a script to load a csv file created by df_dev_generator.\n",
    "    It loads a csv file, drop the 'Unnamed: 0' column and convert the\n",
    "    ts_date column (object) into a column named ds and formated in \n",
    "    local Swiss time (datetime).\n",
    "    \n",
    "    Arg:\n",
    "        - device_nb: String. 2 digit number of the device\n",
    "    \n",
    "    Returns:\n",
    "        - df_dev: dataframe to pass to df_generator\n",
    "    \"\"\"\n",
    "    # Data Loading\n",
    "    file_name = '../Data/interim/device' + str(device_nb) + '_alldays.csv'\n",
    "\n",
    "    df_raw = pd.read_csv(file_name, delimiter=',')\n",
    " \n",
    "    # Clean the dataset\n",
    "    df_raw = df_raw.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "    # Convert ts_date into a datetime and convert UTC into Swiss Time\n",
    "    utc_time = pd.to_datetime(df_raw['ts_date'], format='%Y-%m-%d %H:%M:%S', utc=True)\n",
    "    df_raw['local_time_to_drop'] = utc_time.apply(lambda x: x.tz_convert('Europe/Zurich'))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_raw['ts_date'] = df_raw['local_time_to_drop']\n",
    "    df_raw.rename({'ts_date': 'ds'}, axis=1, inplace=True)\n",
    "    df_dev = df_raw.drop(['local_time_to_drop'],axis=1)\n",
    "    \n",
    "    # Make sure that only the relevant device is included in df_dev\n",
    "    device = df_dev['device'].unique()\n",
    "\n",
    "    return device, df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(dataframe, date, starting_time=None):\n",
    "    \"\"\"\n",
    "    This function allows to find the index for a specific dataframe, date and time.\n",
    "    \n",
    "    Args:\n",
    "        - dataframe: pandas dataframe of interest\n",
    "        - date: string formatted as '2019-04-08'\n",
    "        - time: string formatted as '20:30'. If None, time = '0:00'.\n",
    "    \n",
    "    Print the index\n",
    "    \"\"\"\n",
    "    assert dataframe.shape[0]>0, 'The dataframe is empty !'\n",
    "    \n",
    "    if not starting_time:\n",
    "        starting_time = '0:00' # day time of the first day of the df. Might be relevant to get a full day and help the day/night clustering\n",
    "    \n",
    "    date_str = date + ' ' + starting_time\n",
    "    date_dt = datetime.strptime(date_str,'%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Apply the Swiss time zone. http://pytz.sourceforge.net/#localized-times-and-date-arithmetic\n",
    "    swiss = timezone('Europe/Zurich')\n",
    "    date_dt = swiss.localize(date_dt)\n",
    "\n",
    "    # Filter according to begin and end. Does not take in account the starting time...\n",
    "    date_on = dataframe[(dataframe['ds'] >= date_dt)]\n",
    "    index = date_on.shape[0]\n",
    "    \n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_generator(df_dev, device, parameter, begin, end, sampling_period_st, sampling_period_num, graph=None, predict_day=1):\n",
    "    \"\"\"\n",
    "    This function is generating a new dataframe from entire dataframe.\n",
    "    Note that for now, df_dev is the device 31 specific dataframe.\n",
    "    \n",
    "    Args:\n",
    "        - df_dev: Dataframe. Full dataframe with\n",
    "            o device                                object\n",
    "            o tenant                                object\n",
    "            o ds             datetime64[ns, Europe/Zurich]\n",
    "            o light                                float64\n",
    "            o temperature                          float64\n",
    "            o humidity                             float64\n",
    "            o co2                                  float64\n",
    "        - parameter: String. among 'light', 'temperature', 'humidity', 'co2'.\n",
    "          co2 might be themore \"human-activity\" related\n",
    "        - begin: String. Day of the beginning of the new dataframe.\n",
    "        - end: String. Day of the end of the new dataframe.\n",
    "        - sampling_period_st: String. Duration of bin for data downsampling. ! Format is not accurate for date calculations.\n",
    "        - sampling_period_num: float. Number of hours of the sampling_period_st. Example: resampling every 30min: '0.5\n",
    "    lookback_days: int, optional (default=None)\n",
    "        - graph=None Set to None to show the graph and a value if you don't want to show the graph.\n",
    "        - predict_day=1. Number of days predicted. 1 by default.\n",
    "    \n",
    "    Returns:\n",
    "        df: pandas dataframe for the specific parameter\n",
    "        predict_n = Int. Number of data points to predict.\n",
    "        today_index = df.shape[0] - predict_n # index\n",
    "        lookback_n = int(today_index*0.99) # 1 week 336\n",
    "        \n",
    "    Note: Real values of predict_n, today_index and lookback_n depend on sampling_period. Convert the sampling\n",
    "          period to avoid miscalculations.\n",
    "    \"\"\"\n",
    "    # Saving name\n",
    "    name = str(device) + ': '+ str(parameter) + ' from the ' + str(begin) + ' until the ' + str(end)\n",
    "    \n",
    "    # Prepare the dates\n",
    "    starting_time = '21:00' # day time of the first day of the df. Might be relevant to get a full day and help the day/night clustering\n",
    "    \n",
    "    begin_str = begin + ' ' + starting_time\n",
    "    end_str = end + ' ' + starting_time\n",
    "\n",
    "    begin_dt = datetime.strptime(begin_str,'%Y-%m-%d %H:%M')\n",
    "    end_dt = datetime.strptime(end_str,'%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Apply the Swiss time zone. http://pytz.sourceforge.net/#localized-times-and-date-arithmetic\n",
    "    swiss = timezone('Europe/Zurich')\n",
    "    # swiss.zone\n",
    "    begin_dt = swiss.localize(begin_dt)\n",
    "    end_dt = swiss.localize(end_dt)\n",
    "    \n",
    "    # Sorry this is not elegant. Fix it\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    # Filter according to begin and end. Does not take in account the starting time...\n",
    "    df_full = df_dev[(df_dev['ds'] >= begin_dt) & (df_dev['ds'] <= end_dt)]\n",
    "    \n",
    "    # Generate a parameter-specific df\n",
    "    df_full.rename(columns={parameter: 'y'}, inplace=True)\n",
    "    df_parameter = df_full[['ds', 'y']]\n",
    "\n",
    "    # Set ds as the index\n",
    "    df_parameter.index = df_parameter.ds\n",
    "    df_parameter.reindex # TO DELETE IF IT CRASHES\n",
    "    df_original = df_parameter.copy()\n",
    "    \n",
    "    # Downsampling and fill NaN. Need to have set ds as the index.\n",
    "    df = df_parameter.resample(sampling_period_st).pad() # Disable the pad function to let Prophet deal with missing data\n",
    "#     df = df_parameter.resample(sampling_period) # '30T' --> 30min\n",
    "    df = df.iloc[1:]\n",
    "    \n",
    "    if not graph:\n",
    "        # Plot the df\n",
    "        fig, ax = plt.subplots(figsize=(8,3))\n",
    "        df_original.y.plot(label=\"Original\", color='gray', linewidth=1) # Data with original frequency\n",
    "        df.y.plot(label=\"Resampled data\", color='black', marker='o', linestyle='dashed',linewidth=0.5, markersize=2) \n",
    "\n",
    "        myFmt = DateFormatter(\"%d/%m %H:%M\")\n",
    "        ax.xaxis.set_major_formatter(myFmt)\n",
    "        plt.xlabel('Time', fontsize=8)\n",
    "        plt.ylabel(parameter, fontsize=8)\n",
    "        plt.title(name, fontsize=14)\n",
    "        plt.legend(loc='upper right')\n",
    "        \n",
    "        # vertical lines\n",
    "        begin_str_vl = begin + ' 0:00'\n",
    "        end_str_vl = end + ' 0:00'\n",
    "\n",
    "        begin_dt_vl = datetime.strptime(begin_str_vl,'%Y-%m-%d %H:%M') + timedelta(days=1)\n",
    "        end_dt_vl = datetime.strptime(end_str_vl,'%Y-%m-%d %H:%M')\n",
    "        \n",
    "        begin_dt_vl = swiss.localize(begin_dt_vl)\n",
    "        end_dt_vl = swiss.localize(end_dt_vl)\n",
    "    \n",
    "        daterange = pd.date_range(begin_dt_vl, end_dt_vl)\n",
    "        for single_date in daterange:\n",
    "            plt.axvline(x=single_date, color='lightseagreen', linestyle='--')\n",
    "        plt.show()\n",
    "        \n",
    "#         # If you want to save the file\n",
    "#         folder = '/Users/guillaume/Documents/DS2020/Caru/caru/figures/'\n",
    "#         filename = folder + name + '.png'\n",
    "#         plt.savefig(filename, bbox_inches = \"tight\")\n",
    "#     else:\n",
    "#         None\n",
    "\n",
    "    # Shape report\n",
    "    last_df = df.shape[0]-1\n",
    "    last = df_dev.shape[0]-1\n",
    "#     bining_frequency = 30  # Integer. Sampling period in min. Example 30T --> 30.\n",
    "#     nb_of_days = int(df.shape[0]/((60/bining_frequency)*24))\n",
    "    print('Full dataset: {:%Y-%m-%d} to the {:%Y-%m-%d}. Analysed data the {:%Y-%m-%d} to the {:%Y-%m-%d}.'\n",
    "          .format(df_dev['ds'][0], df_dev['ds'][last], df['ds'][0], df['ds'][last_df]))\n",
    "#     print('Full dataset: {:%Y-%m-%d} to the {:%Y-%m-%d}. Analysed data the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'\n",
    "#           .format(df_dev['ds'][0], df_dev['ds'][last], df['ds'][0], df['ds'][last_df]), nb_of_days)\n",
    "    \n",
    "    # specify the time frames. Note: current binning is 30min\n",
    "    predict_n = int(predict_day*24/sampling_period_num) # in data points\n",
    "    today_index = df.shape[0] - predict_n # index\n",
    "    lookback_n = int(today_index*0.99) # 1 week 336\n",
    "    \n",
    "    return df, predict_n, today_index, lookback_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility functions of Prophet\n",
    "# Code reference: https://github.com/paullo0106/prophet_anomaly_detection/blob/master/utils.py\n",
    "\n",
    "def prophet_fit(df, prophet_model, today_index, sampling_period_st, sampling_period_num, lookback_days=None, predict_days=21):\n",
    "    \"\"\"\n",
    "    Fit the model to the time-series data and generate forecast for specified time frames\n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    prophet_model : Prophet model\n",
    "        Prophet model with configured parameters\n",
    "    today_index : int\n",
    "        The index of the date list in the df dataframe, where Day (today_index-lookback_days)th\n",
    "        to Day (today_index-1)th is the time frame for training\n",
    "    sampling_period_st: string. Period of resampling.\n",
    "        Relevant parameter for make_future_dataframe. Example: resampling every 30min: '30T'\n",
    "    sampling_period_num: float. Number of hours of the sampling_period_st. Example: resampling every 30min: '0.5\n",
    "    lookback_days: int, optional (default=None)\n",
    "        As described above, use all the available dates until today_index as\n",
    "        training set if no value assigned\n",
    "    predict_days: int, optional (default=21)\n",
    "        Make prediction for Day (today_index)th to Day (today_index+predict_days)th\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib Figure\n",
    "        A plot with actual data, predicted values and the interval\n",
    "    forecast : pandas DataFrame\n",
    "        The predicted result in a format of dataframe\n",
    "    prophet_model : Prophet model\n",
    "        Trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # segment the time frames\n",
    "    lookback_days_show = int(lookback_days/(24/sampling_period_num))\n",
    "    predict_days_show = int(predict_days/(24/sampling_period_num))\n",
    "    \n",
    "    baseline_ts = df['ds'][:today_index]\n",
    "    baseline_y = df['y'][:today_index]\n",
    "    if not lookback_days:\n",
    "        print('o Trained on data from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][0],\n",
    "                                                            df['ds'][today_index - 1],\n",
    "                                                            lookback_days_show))\n",
    "    else:\n",
    "        baseline_ts = df['ds'][today_index - lookback_days:today_index]\n",
    "        baseline_y = df.y[today_index - lookback_days:today_index]\n",
    "        print('o Trained on the data from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][today_index - lookback_days],\n",
    "                                                            df['ds'][today_index - 1],\n",
    "                                                            lookback_days_show))\n",
    "    print('o Predict from the {:%Y-%m-%d} to the {:%Y-%m-%d} ({} days).'.format(df['ds'][today_index],\n",
    "                                              df['ds'][today_index + predict_days - 1],\n",
    "                                              predict_days_show))\n",
    "\n",
    "    # fit the model\n",
    "    prophet_model.fit(pd.DataFrame({'ds': baseline_ts.values,\n",
    "                                    'y': baseline_y.values}))\n",
    "    \n",
    "    # make prediction. Note that the frequency of the sampling period used for the dataframe\n",
    "    # To make a new frequency, check \n",
    "    # https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "    future = prophet_model.make_future_dataframe(periods=predict_days, freq = sampling_period_st)\n",
    "#     future = prophet_model.make_future_dataframe(periods=predict_days, freq = '30T') \n",
    "    forecast = prophet_model.predict(future)\n",
    "    \n",
    "    # generate the plot\n",
    "    fig = prophet_model.plot(forecast)\n",
    "    return fig, forecast, prophet_model\n",
    "\n",
    "\n",
    "def prophet_plot(df, fig, today_index, lookback_days=None, predict_days=21, outliers=list()):\n",
    "    \"\"\"\n",
    "    Plot the actual, predictions, and anomalous values\n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    fig : matplotlib Figure\n",
    "        A plot with actual data, predicted values and the interval which we previously obtained\n",
    "        from Prophet's model.plot(forecast).\n",
    "    today_index : int\n",
    "        The index of the date list in the dataframe dividing the baseline and prediction time frames.\n",
    "    lookback_days : int, optional (default=None)\n",
    "        Day (today_index-lookback_days)th to Day (today_index-1)th is the baseline time frame for training.\n",
    "    predict_days : int, optional (default=21)\n",
    "        Make prediction for Day (today_index)th to Day (today_index+predict_days)th.\n",
    "    outliers : a list of (datetime, int) tuple\n",
    "        The outliers we want to highlight on the plot.\n",
    "    \"\"\"\n",
    "    # retrieve the subplot in the generated Prophets matplotlib figure\n",
    "    ax = fig.get_axes()[0]\n",
    "\n",
    "    start = 0\n",
    "#     end = today_index + predict_days # Original code\n",
    "    end = df.shape[0]\n",
    "    x_pydatetime = df['ds'].dt.to_pydatetime()\n",
    "    # highlight the actual values of the entire time frame\n",
    "    ax.plot(x_pydatetime[start:end],\n",
    "            df.y[start:end],\n",
    "            color='orange', label='Actual')\n",
    "\n",
    "    # plot each outlier in red dot and annotate the date\n",
    "    for outlier in outliers:\n",
    "        ax.scatter(outlier[0], outlier[1], s=16, color='red', label='Anomaly')\n",
    "#         ax.text(outlier[0], outlier[1], str(outlier[0])[:10], color='red', fontsize=6)\n",
    "\n",
    "    # highlight baseline time frame with gray background\n",
    "    if lookback_days:\n",
    "        start = today_index - lookback_days\n",
    "    ax.axvspan(x_pydatetime[start],\n",
    "               x_pydatetime[today_index],\n",
    "               color=sns.xkcd_rgb['grey'],\n",
    "               alpha=0.2)\n",
    "\n",
    "    # annotate the areas, and position the text at the bottom 5% by using ymin + (ymax - ymin) / 20\n",
    "    ymin, ymax = ax.get_ylim()[0], ax.get_ylim()[1]\n",
    "    ax.text(x_pydatetime[int((start + today_index) / 2)], ymin + (ymax - ymin) / 20, 'Baseline area')\n",
    "    ax.text(x_pydatetime[int((today_index * 2 + predict_days) / 2)], ymin + (ymax - ymin) / 20, 'Prediction area')\n",
    "\n",
    "    # re-organize the legend\n",
    "    patch1 = mpatches.Patch(color='red', label='Anomaly')\n",
    "    patch2 = mpatches.Patch(color='orange', label='Actual')\n",
    "    patch3 = mpatches.Patch(color='skyblue', label='Predict and interval')\n",
    "    patch4 = mpatches.Patch(color='grey', label='Baseline area')\n",
    "    plt.legend(handles=[patch1, patch2, patch3, patch4])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_outliers(df, forecast, today_index, predict_days=21):\n",
    "    \"\"\"\n",
    "    Combine the actual values and forecast in a data frame and identify the outliers\n",
    "    Args\n",
    "    ----\n",
    "    df : pandas DataFrame\n",
    "        The daily time-series data set contains ds column for\n",
    "        dates (datetime types such as datetime64[ns]) and y column for numerical values\n",
    "    forecast : pandas DataFrame\n",
    "        The predicted result in a dataframe which was previously generated by\n",
    "        Prophet's model.predict(future)\n",
    "    today_index : int\n",
    "        The summary statistics of the right tree node.\n",
    "    predict_days : int, optional (default=21)\n",
    "        The time frame we segment as prediction period\n",
    "    Returns\n",
    "    -------\n",
    "    outliers : a list of (datetime, int) tuple\n",
    "        A list of outliers, the date and the value for each\n",
    "    df_pred : pandas DataFrame\n",
    "        The data set contains actual and predictions for the forecast time frame\n",
    "    \"\"\"\n",
    "    df_pred = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(predict_days)\n",
    "    df_pred.index = df_pred['ds'].dt.to_pydatetime()\n",
    "    df_pred.columns = ['ds', 'preds', 'lower_y', 'upper_y']\n",
    "    df_pred['actual'] = df['y'][today_index: today_index + predict_days].values\n",
    "\n",
    "    # construct a list of outliers\n",
    "    outlier_index = list()\n",
    "    outliers = list()\n",
    "    for i in range(df_pred.shape[0]):\n",
    "        actual_value = df_pred['actual'][i]\n",
    "        if actual_value < df_pred['lower_y'][i] or actual_value > df_pred['upper_y'][i]:\n",
    "            outlier_index += [i]\n",
    "            outliers.append((df_pred.index[i], actual_value))\n",
    "            # optional, print out the evaluation for each outlier\n",
    "#             print('=====')\n",
    "#             print('actual value {} fall outside of the prediction interval'.format(actual_value))\n",
    "#             print('interval: {} to {}'.format(df_pred['lower_y'][i], df_pred['upper_y'][i]))\n",
    "#             print('Date: {}'.format(str(df_pred.index[i])[:10]))\n",
    "\n",
    "    return outliers, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_cross_validation_and_performance_loop(cross_valid_params, metric = 'mse'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Execute Cross Validation and Performance Loop\n",
    "    Parameters\n",
    "    ----------\n",
    "    cross_valid_params: List of dict\n",
    "      dict value same as cross_validation function argument\n",
    "      model, horizon, period, initial\n",
    "    metric: string \n",
    "      sort the dataframe in ascending order base on the \n",
    "      performance metric of your choice either mse, rmse, mae or mape\n",
    "    Returns\n",
    "    -------\n",
    "    A pd.DataFrame with cross_validation result. One row\n",
    "    per different configuration sorted ascending base on\n",
    "    the metric inputed by the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert metric in ['mse','rmse','mae','mape'], \\\n",
    "                    'metric must be either mse, rmse, mae or mape'\n",
    "\n",
    "    df_ps = pd.DataFrame()\n",
    "\n",
    "    for cross_valid_param in cross_valid_params:\n",
    "        df_cv = cross_validation(**cross_valid_param)\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        df_p['initial'] = cross_valid_param['initial']\n",
    "        df_p['period'] = cross_valid_param['period']\n",
    "        df_ps = df_ps.append(df_p)\n",
    "    \n",
    "    df_ps = df_ps[['initial','horizon','period','mse'\n",
    "                    ,'rmse','mae','mape','coverage']]\n",
    "    return df_ps.sort_values(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gv378tcGbWDl"
   },
   "source": [
    "### Load data from the Amazon S3 bucket:\n",
    "\n",
    "[Link to the caru bucket on Amazon](https://s3.console.aws.amazon.com/s3/buckets/carudata/?region=eu-north-1&tab=overview) *(credentials required)*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import boto3, os\n",
    "import s3fs\n",
    "s3 = boto3.client('s3') # aws client object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = 's3://carudata/interim/device04_alldays.csv'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load local file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('Starting loading...\\n\\n Typical loading of formated_df_20200331.csv takes 90sec.')\n",
    "df_raw = pd.read_csv('../Data/full_df_20200331.csv', delimiter=',')\n",
    "end_time = time.time()\n",
    "\n",
    "print('full_df_20200331.csv loaded in df_raw in '+ str(int(end_time - start_time)) + \" seconds.\\n Below are the first lines\")\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check report:\n",
      "##############################################\n",
      "['\\nDevice contained in the dataset: device33']\n",
      "['Tenant using the device: tenant09']\n",
      "\n",
      "There are 236187 lines.\n",
      "\n",
      "Data types:\n",
      "device                                object\n",
      "tenant                                object\n",
      "ds             datetime64[ns, Europe/Zurich]\n",
      "light                                float64\n",
      "temperature                          float64\n",
      "humidity                             float64\n",
      "co2                                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "device_nb = '33' # 2-digit number !\n",
    "device, df_dev = df_dev_formater(device_nb)\n",
    "\n",
    "assert device.shape[0]==1, 'No, or several devices in the df'\n",
    "\n",
    "# Check report:\n",
    "print('Check report:\\n##############################################')\n",
    "print('\\nDevice contained in the dataset: ' + device)\n",
    "print('Tenant using the device: ' + df_dev['tenant'].unique())\n",
    "print('\\nThere are ' + str(df_dev.shape[0]) + ' lines.')\n",
    "print('\\nData types:')\n",
    "print(df_dev.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0184b2b3ef29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbf454cd4724980ba062b6818abed23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-07 to the 2019-05-01.\n"
     ]
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-07', '2019-05-01', '30T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c764d2f5623e45c4bb0e71eec6db443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-26 to the 2019-04-03.\n"
     ]
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-26', '2019-04-03', '60T')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_extreme_removed\n",
    "df = df_generator(df_extreme_removed, device, 'co2', '2019-04-01', '2019-04-11', '300T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    }
   ],
   "source": [
    "find_index(df, '2019-03-08', '20:30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2FVJ7cvKTjl"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1: Testing different parameters of the fitting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3b4956d28a4b82ac445c04d6df894c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-18 to the 2019-03-26.\n",
      "o Trained on the data from the 2019-03-18 to the 2019-03-25 (8 days).\n",
      "o Predict from the 2019-03-25 to the 2019-03-26 (1 days).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/fbprophet/plot.py:66: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae73a34976ab4226acb668ba401937e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 6 forecasts with cutoffs between 2019-03-22 08:09:40.249000 and 2019-03-24 20:09:40.249000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>40033.90766</td>\n",
       "      <td>200.084751</td>\n",
       "      <td>128.64031</td>\n",
       "      <td>0.207634</td>\n",
       "      <td>0.369942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial horizon    period          mse        rmse        mae      mape  \\\n",
       "0  3 days  1 days  0.5 days  40033.90766  200.084751  128.64031  0.207634   \n",
       "\n",
       "   coverage  \n",
       "0  0.369942  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-18', '2019-03-26', '25T', 0.42, graph=None, predict_day=1)\n",
    "#                                         df_generator(df_dev, device, parameter, begin, end, sampling_period_st, sampling_period_num, graph=None, predict_day=1):\n",
    "\n",
    "# You can manually specify the time frames: (predict_n, today_index and lookback_n). Note: current binning is 30min.\n",
    "\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. should be <0.1 low --> toward overfit\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=12) # prior scale\n",
    "# model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, '30T', 0.5, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)\n",
    "plt.show()\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['3 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days']} # A forecast is made for every observed point between cutoff and cutoff + horizon\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d148947c671240f691ce674eb470d2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-18 to the 2019-03-26.\n",
      "o Trained on the data from the 2019-03-18 to the 2019-03-25 (6 days).\n",
      "o Predict from the 2019-03-25 to the 2019-03-26 (1 days).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/fbprophet/plot.py:66: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5460056c6d78454a8aa11f874adf5a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 6 forecasts with cutoffs between 2019-03-22 06:54:46.463000 and 2019-03-24 18:54:46.463000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>30256.419042</td>\n",
       "      <td>173.943724</td>\n",
       "      <td>103.853679</td>\n",
       "      <td>0.170345</td>\n",
       "      <td>0.414691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial horizon    period           mse        rmse         mae      mape  \\\n",
       "0  3 days  1 days  0.5 days  30256.419042  173.943724  103.853679  0.170345   \n",
       "\n",
       "   coverage  \n",
       "0  0.414691  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-18', '2019-03-26', '5T', 0.08, graph=None, predict_day=1)\n",
    "# You can manually specify the time frames: (predict_n, today_index and lookback_n). Note: current binning is 30min.\n",
    "\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. should be <0.1 low --> toward overfit\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=12) # prior scale\n",
    "# model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, '5T', 0.08, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)\n",
    "plt.show()\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['3 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days']} # A forecast is made for every observed point between cutoff and cutoff + horizon}\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e40009b49954125b42f543ab0fb7391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-17 to the 2019-03-24.\n",
      "o Trained on the data from the 2019-03-17 to the 2019-03-23 (5 days).\n",
      "o Predict from the 2019-03-23 to the 2019-03-24 (1 days).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbd75e8efc7462d92e680c88047494d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 4 forecasts with cutoffs between 2019-03-21 06:54:53.676000 and 2019-03-22 18:54:53.676000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>14944.494048</td>\n",
       "      <td>122.247675</td>\n",
       "      <td>99.856708</td>\n",
       "      <td>0.184994</td>\n",
       "      <td>0.501736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial horizon    period           mse        rmse        mae      mape  \\\n",
       "0  3 days  1 days  0.5 days  14944.494048  122.247675  99.856708  0.184994   \n",
       "\n",
       "   coverage  \n",
       "0  0.501736  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-17', '2019-03-24', '5T', 0.08, graph=None, predict_day=1)\n",
    "# You can manually specify the time frames: (predict_n, today_index and lookback_n). Note: current binning is 30min.\n",
    "\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.9, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. should be <0.1 low --> toward overfit\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=12) # prior scale\n",
    "# model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, '5T', 0.08, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)\n",
    "plt.show()\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['3 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days']} # A forecast is made for every observed point between cutoff and cutoff + horizon}\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803931951f324ad7b26ecd11b58b95b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-14 to the 2019-03-21.\n",
      "o Trained on the data from the 2019-03-14 to the 2019-03-20 (5 days).\n",
      "o Predict from the 2019-03-20 to the 2019-03-21 (1 days).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/fbprophet/plot.py:66: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173cfcd9eba1499298fc3d34af43fcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 4 forecasts with cutoffs between 2019-03-18 06:54:54.282000 and 2019-03-19 18:54:54.282000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>14914.094321</td>\n",
       "      <td>122.123275</td>\n",
       "      <td>101.971818</td>\n",
       "      <td>0.190647</td>\n",
       "      <td>0.321769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial horizon    period           mse        rmse         mae      mape  \\\n",
       "0  3 days  1 days  0.5 days  14914.094321  122.123275  101.971818  0.190647   \n",
       "\n",
       "   coverage  \n",
       "0  0.321769  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-14', '2019-03-21', '5T', 0.08, graph=None, predict_day=1)\n",
    "# You can manually specify the time frames: (predict_n, today_index and lookback_n). Note: current binning is 30min.\n",
    "\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. should be <0.1 low --> toward overfit\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=12) # prior scale\n",
    "# model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, '5T', 0.08, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)\n",
    "plt.show()\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['3 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days']} # A forecast is made for every observed point between cutoff and cutoff + horizon}\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e140d53df88a48c5990e093faa3fb621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: 2019-03-07 to the 2019-05-01. Analysed data the 2019-03-18 to the 2019-03-26.\n",
      "o Trained on the data from the 2019-03-18 to the 2019-03-25 (6 days).\n",
      "o Predict from the 2019-03-25 to the 2019-03-26 (1 days).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/fbprophet/plot.py:66: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cde212273e45f2aa1d605f224d8e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 6 forecasts with cutoffs between 2019-03-22 06:58:47.166000 and 2019-03-24 18:58:47.166000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>29373.252572</td>\n",
       "      <td>171.386267</td>\n",
       "      <td>112.673275</td>\n",
       "      <td>0.19097</td>\n",
       "      <td>0.478417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  initial horizon    period           mse        rmse         mae     mape  \\\n",
       "0  3 days  1 days  0.5 days  29373.252572  171.386267  112.673275  0.19097   \n",
       "\n",
       "   coverage  \n",
       "0  0.478417  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, predict_n, today_index, lookback_n = df_generator(df_dev, device, 'co2', '2019-03-18', '2019-03-26', '1T', 0.016, graph=None, predict_day=1)\n",
    "#                                         df_generator(df_dev, device, parameter, begin, end, sampling_period_st, sampling_period_num, graph=None, predict_day=1):\n",
    "\n",
    "# You can manually specify the time frames: (predict_n, today_index and lookback_n). Note: current binning is 30min.\n",
    "\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. should be <0.1 low --> toward overfit\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=12) # prior scale\n",
    "# model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, '1T', 0.016, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)\n",
    "plt.show()\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['3 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days']} # A forecast is made for every observed point between cutoff and cutoff + horizon}\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Model evaluation\n",
    "\n",
    "**cross_validation:**\n",
    "\n",
    "* Diagnose the pattern with time-series decomposition\n",
    "* Look at performance metrics including MSE, RMSE, MAP, MAPE (see [Prophet docs](https://facebook.github.io/prophet/docs/diagnostics.html) for details)\n",
    "\n",
    "*What it does:*\n",
    "* Generate a dataframe of forecasts.\n",
    "* Provide warnings and an explicit sentence describing the result of cross-validation.\n",
    "\n",
    "*Args:*\n",
    "- model: Prophet model defined above.\n",
    "- initial: String formated as 'n days', where n is a number of days. Define the first day taken in account for cross-validation.\n",
    "- period: Same format as initial. Spacing between cutoff dates.\n",
    "- horizon: Same format as initial. Duration of prediction. A forecast is made for every observed point between cutoff and cutoff + horizon\n",
    "    \n",
    "*Returns:*\n",
    "- dataframe containing: time (ds), predicted value, predicted value -  tolerance, predicted value +  tolerance, real value\n",
    "- Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 24 forecasts with cutoffs between 2019-03-20 06:29:47.191000 and 2019-03-31 18:29:47.191000\n",
      "INFO:fbprophet:Making 12 forecasts with cutoffs between 2019-03-26 06:29:47.191000 and 2019-03-31 18:29:47.191000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>horizon</th>\n",
       "      <th>period</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>7943.206990</td>\n",
       "      <td>89.124671</td>\n",
       "      <td>76.908726</td>\n",
       "      <td>0.126626</td>\n",
       "      <td>0.196181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.5 days</td>\n",
       "      <td>9741.611008</td>\n",
       "      <td>98.699600</td>\n",
       "      <td>81.724256</td>\n",
       "      <td>0.131423</td>\n",
       "      <td>0.198785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial horizon    period          mse       rmse        mae      mape  \\\n",
       "0  12 days  1 days  0.5 days  7943.206990  89.124671  76.908726  0.126626   \n",
       "0   6 days  1 days  0.5 days  9741.611008  98.699600  81.724256  0.131423   \n",
       "\n",
       "   coverage  \n",
       "0  0.196181  \n",
       "0  0.198785  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prophet Auto Selection with Cross-Validation\n",
    "# https://medium.com/@jeanphilippemallette/prophet-auto-selection-with-cross-validation-7ba2c0a3beef\n",
    "\n",
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['6 days', '12 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days'] # A forecast is made for every observed point between cutoff and cutoff + horizon\n",
    "             }\n",
    "execute_cross_validation_and_performance_loop(list(ParameterGrid(param_grid)), metric = 'mape')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'model' : [model],\n",
    "              'initial' : ['1 days', '4 days', '8 days'], # If not provided, 3 * horizon is used. Same units as horizon\n",
    "              'period'  : ['0.5 days', '1 days'], # Integer amount of time between cutoff dates. If not provided, 0.5 * horizon is used.\n",
    "              'horizon' : ['1 days'] # A forecast is made for every observed point between cutoff and cutoff + horizon\n",
    "             }\n",
    "list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 1 forecasts with cutoffs between 2019-03-31 18:29:47.191000 and 2019-03-31 18:29:47.191000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>y</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-31 18:59:45.570</td>\n",
       "      <td>683.905068</td>\n",
       "      <td>650.759408</td>\n",
       "      <td>717.675911</td>\n",
       "      <td>777.272217</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-31 19:29:51.141</td>\n",
       "      <td>671.735730</td>\n",
       "      <td>638.584357</td>\n",
       "      <td>704.417639</td>\n",
       "      <td>827.711670</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-31 19:59:56.747</td>\n",
       "      <td>660.789592</td>\n",
       "      <td>623.220048</td>\n",
       "      <td>694.387207</td>\n",
       "      <td>813.223389</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-31 20:29:42.241</td>\n",
       "      <td>656.051737</td>\n",
       "      <td>618.687834</td>\n",
       "      <td>687.363459</td>\n",
       "      <td>788.340698</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-31 20:59:47.836</td>\n",
       "      <td>652.793015</td>\n",
       "      <td>619.439320</td>\n",
       "      <td>691.339024</td>\n",
       "      <td>747.890747</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds        yhat  yhat_lower  yhat_upper           y  \\\n",
       "0 2019-03-31 18:59:45.570  683.905068  650.759408  717.675911  777.272217   \n",
       "1 2019-03-31 19:29:51.141  671.735730  638.584357  704.417639  827.711670   \n",
       "2 2019-03-31 19:59:56.747  660.789592  623.220048  694.387207  813.223389   \n",
       "3 2019-03-31 20:29:42.241  656.051737  618.687834  687.363459  788.340698   \n",
       "4 2019-03-31 20:59:47.836  652.793015  619.439320  691.339024  747.890747   \n",
       "\n",
       "                   cutoff  \n",
       "0 2019-03-31 18:29:47.191  \n",
       "1 2019-03-31 18:29:47.191  \n",
       "2 2019-03-31 18:29:47.191  \n",
       "3 2019-03-31 18:29:47.191  \n",
       "4 2019-03-31 18:29:47.191  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv = cross_validation(model, period='15 days', horizon = '1 days')\n",
    "df_cv.head()\n",
    "# df_p = performance_metrics(df_cv)\n",
    "# df_p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 6)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>yhat</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>y</th>\n",
       "      <th>cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-31 18:59:45.570</td>\n",
       "      <td>683.905068</td>\n",
       "      <td>650.759408</td>\n",
       "      <td>717.675911</td>\n",
       "      <td>777.272217</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-31 19:29:51.141</td>\n",
       "      <td>671.735730</td>\n",
       "      <td>638.584357</td>\n",
       "      <td>704.417639</td>\n",
       "      <td>827.711670</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-31 19:59:56.747</td>\n",
       "      <td>660.789592</td>\n",
       "      <td>623.220048</td>\n",
       "      <td>694.387207</td>\n",
       "      <td>813.223389</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-31 20:29:42.241</td>\n",
       "      <td>656.051737</td>\n",
       "      <td>618.687834</td>\n",
       "      <td>687.363459</td>\n",
       "      <td>788.340698</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-31 20:59:47.836</td>\n",
       "      <td>652.793015</td>\n",
       "      <td>619.439320</td>\n",
       "      <td>691.339024</td>\n",
       "      <td>747.890747</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-03-31 21:29:53.355</td>\n",
       "      <td>652.003341</td>\n",
       "      <td>613.669807</td>\n",
       "      <td>685.787231</td>\n",
       "      <td>748.530518</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-03-31 21:59:58.891</td>\n",
       "      <td>636.756699</td>\n",
       "      <td>600.766159</td>\n",
       "      <td>669.678200</td>\n",
       "      <td>737.236633</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-03-31 22:29:44.276</td>\n",
       "      <td>634.464961</td>\n",
       "      <td>601.683510</td>\n",
       "      <td>671.789058</td>\n",
       "      <td>778.416260</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-31 22:59:49.830</td>\n",
       "      <td>639.099277</td>\n",
       "      <td>600.974199</td>\n",
       "      <td>672.182128</td>\n",
       "      <td>757.523132</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-31 23:29:55.410</td>\n",
       "      <td>624.290491</td>\n",
       "      <td>587.080293</td>\n",
       "      <td>655.761476</td>\n",
       "      <td>752.032898</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-03-31 23:59:40.756</td>\n",
       "      <td>621.406697</td>\n",
       "      <td>586.038259</td>\n",
       "      <td>657.637934</td>\n",
       "      <td>737.980774</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-04-01 00:29:46.203</td>\n",
       "      <td>626.986409</td>\n",
       "      <td>589.828289</td>\n",
       "      <td>659.803361</td>\n",
       "      <td>742.128967</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-04-01 00:59:51.822</td>\n",
       "      <td>630.097393</td>\n",
       "      <td>598.043026</td>\n",
       "      <td>670.014867</td>\n",
       "      <td>748.124329</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-04-01 01:29:57.302</td>\n",
       "      <td>622.023223</td>\n",
       "      <td>586.565311</td>\n",
       "      <td>659.595112</td>\n",
       "      <td>771.856628</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-04-01 01:59:42.725</td>\n",
       "      <td>615.933511</td>\n",
       "      <td>581.830267</td>\n",
       "      <td>650.264468</td>\n",
       "      <td>814.264954</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-04-01 02:29:48.307</td>\n",
       "      <td>622.505372</td>\n",
       "      <td>588.175986</td>\n",
       "      <td>660.768921</td>\n",
       "      <td>773.681396</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-04-01 02:59:54.128</td>\n",
       "      <td>614.163079</td>\n",
       "      <td>581.869279</td>\n",
       "      <td>652.158456</td>\n",
       "      <td>737.249268</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-04-01 03:29:59.808</td>\n",
       "      <td>604.715637</td>\n",
       "      <td>574.866484</td>\n",
       "      <td>645.336379</td>\n",
       "      <td>698.360413</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-04-01 03:59:45.196</td>\n",
       "      <td>601.174522</td>\n",
       "      <td>568.744263</td>\n",
       "      <td>640.171460</td>\n",
       "      <td>679.320312</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-04-01 04:29:50.706</td>\n",
       "      <td>596.479960</td>\n",
       "      <td>556.942713</td>\n",
       "      <td>628.961346</td>\n",
       "      <td>666.293579</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-04-01 04:59:56.131</td>\n",
       "      <td>592.760586</td>\n",
       "      <td>561.879880</td>\n",
       "      <td>634.284047</td>\n",
       "      <td>656.462280</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-04-01 05:29:41.529</td>\n",
       "      <td>594.885325</td>\n",
       "      <td>560.940018</td>\n",
       "      <td>631.516360</td>\n",
       "      <td>652.773254</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-04-01 05:59:47.608</td>\n",
       "      <td>598.507979</td>\n",
       "      <td>568.850671</td>\n",
       "      <td>633.502630</td>\n",
       "      <td>645.244690</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-04-01 06:29:53.089</td>\n",
       "      <td>587.799318</td>\n",
       "      <td>550.826846</td>\n",
       "      <td>621.210245</td>\n",
       "      <td>672.942444</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-04-01 06:59:58.484</td>\n",
       "      <td>583.993537</td>\n",
       "      <td>546.209617</td>\n",
       "      <td>616.041753</td>\n",
       "      <td>662.727661</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-04-01 07:29:43.896</td>\n",
       "      <td>585.043183</td>\n",
       "      <td>549.774814</td>\n",
       "      <td>620.698559</td>\n",
       "      <td>692.804077</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-04-01 07:59:49.389</td>\n",
       "      <td>580.910694</td>\n",
       "      <td>543.131498</td>\n",
       "      <td>614.097852</td>\n",
       "      <td>661.217163</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-04-01 08:29:55.074</td>\n",
       "      <td>576.694490</td>\n",
       "      <td>544.091156</td>\n",
       "      <td>618.576555</td>\n",
       "      <td>638.817505</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-04-01 08:59:40.980</td>\n",
       "      <td>578.712538</td>\n",
       "      <td>544.206514</td>\n",
       "      <td>615.519523</td>\n",
       "      <td>627.899048</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-04-01 09:29:46.541</td>\n",
       "      <td>591.190101</td>\n",
       "      <td>557.477690</td>\n",
       "      <td>623.727014</td>\n",
       "      <td>701.850952</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-04-01 09:59:52.136</td>\n",
       "      <td>590.957108</td>\n",
       "      <td>557.308957</td>\n",
       "      <td>628.634890</td>\n",
       "      <td>499.714874</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-04-01 10:29:57.754</td>\n",
       "      <td>601.818628</td>\n",
       "      <td>566.074808</td>\n",
       "      <td>633.630846</td>\n",
       "      <td>489.762726</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-04-01 10:59:43.186</td>\n",
       "      <td>618.773888</td>\n",
       "      <td>584.497923</td>\n",
       "      <td>656.772077</td>\n",
       "      <td>482.349274</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-04-01 11:29:48.927</td>\n",
       "      <td>613.624088</td>\n",
       "      <td>578.848473</td>\n",
       "      <td>649.211322</td>\n",
       "      <td>493.256592</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-04-01 11:59:54.446</td>\n",
       "      <td>612.861753</td>\n",
       "      <td>579.805967</td>\n",
       "      <td>648.747033</td>\n",
       "      <td>548.395203</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-04-01 12:29:39.937</td>\n",
       "      <td>616.367849</td>\n",
       "      <td>581.810771</td>\n",
       "      <td>652.498241</td>\n",
       "      <td>530.254333</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-04-01 12:59:45.495</td>\n",
       "      <td>623.472605</td>\n",
       "      <td>588.323788</td>\n",
       "      <td>658.900426</td>\n",
       "      <td>508.934387</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-04-01 13:29:51.048</td>\n",
       "      <td>628.493011</td>\n",
       "      <td>595.131208</td>\n",
       "      <td>664.135405</td>\n",
       "      <td>566.080872</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-04-01 13:59:56.627</td>\n",
       "      <td>636.485221</td>\n",
       "      <td>599.969225</td>\n",
       "      <td>673.920040</td>\n",
       "      <td>540.026001</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-04-01 14:29:42.131</td>\n",
       "      <td>652.756380</td>\n",
       "      <td>619.805001</td>\n",
       "      <td>687.379448</td>\n",
       "      <td>488.786652</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-04-01 14:59:47.764</td>\n",
       "      <td>654.879270</td>\n",
       "      <td>620.200151</td>\n",
       "      <td>693.447117</td>\n",
       "      <td>530.235413</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-04-01 15:29:53.479</td>\n",
       "      <td>659.077679</td>\n",
       "      <td>622.895967</td>\n",
       "      <td>693.563904</td>\n",
       "      <td>504.406006</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-04-01 15:59:59.076</td>\n",
       "      <td>663.656168</td>\n",
       "      <td>623.396055</td>\n",
       "      <td>696.697922</td>\n",
       "      <td>496.006592</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-04-01 16:29:44.590</td>\n",
       "      <td>655.252029</td>\n",
       "      <td>618.598934</td>\n",
       "      <td>686.672549</td>\n",
       "      <td>504.519226</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-04-01 16:59:50.167</td>\n",
       "      <td>647.014705</td>\n",
       "      <td>610.193418</td>\n",
       "      <td>682.270454</td>\n",
       "      <td>486.087738</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-04-01 17:29:55.660</td>\n",
       "      <td>661.060433</td>\n",
       "      <td>625.393212</td>\n",
       "      <td>694.007395</td>\n",
       "      <td>557.952515</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-04-01 17:59:41.194</td>\n",
       "      <td>689.951212</td>\n",
       "      <td>654.596936</td>\n",
       "      <td>725.059914</td>\n",
       "      <td>565.191040</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-04-01 18:29:47.191</td>\n",
       "      <td>696.843086</td>\n",
       "      <td>659.139517</td>\n",
       "      <td>729.758704</td>\n",
       "      <td>577.450500</td>\n",
       "      <td>2019-03-31 18:29:47.191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ds        yhat  yhat_lower  yhat_upper           y  \\\n",
       "0  2019-03-31 18:59:45.570  683.905068  650.759408  717.675911  777.272217   \n",
       "1  2019-03-31 19:29:51.141  671.735730  638.584357  704.417639  827.711670   \n",
       "2  2019-03-31 19:59:56.747  660.789592  623.220048  694.387207  813.223389   \n",
       "3  2019-03-31 20:29:42.241  656.051737  618.687834  687.363459  788.340698   \n",
       "4  2019-03-31 20:59:47.836  652.793015  619.439320  691.339024  747.890747   \n",
       "5  2019-03-31 21:29:53.355  652.003341  613.669807  685.787231  748.530518   \n",
       "6  2019-03-31 21:59:58.891  636.756699  600.766159  669.678200  737.236633   \n",
       "7  2019-03-31 22:29:44.276  634.464961  601.683510  671.789058  778.416260   \n",
       "8  2019-03-31 22:59:49.830  639.099277  600.974199  672.182128  757.523132   \n",
       "9  2019-03-31 23:29:55.410  624.290491  587.080293  655.761476  752.032898   \n",
       "10 2019-03-31 23:59:40.756  621.406697  586.038259  657.637934  737.980774   \n",
       "11 2019-04-01 00:29:46.203  626.986409  589.828289  659.803361  742.128967   \n",
       "12 2019-04-01 00:59:51.822  630.097393  598.043026  670.014867  748.124329   \n",
       "13 2019-04-01 01:29:57.302  622.023223  586.565311  659.595112  771.856628   \n",
       "14 2019-04-01 01:59:42.725  615.933511  581.830267  650.264468  814.264954   \n",
       "15 2019-04-01 02:29:48.307  622.505372  588.175986  660.768921  773.681396   \n",
       "16 2019-04-01 02:59:54.128  614.163079  581.869279  652.158456  737.249268   \n",
       "17 2019-04-01 03:29:59.808  604.715637  574.866484  645.336379  698.360413   \n",
       "18 2019-04-01 03:59:45.196  601.174522  568.744263  640.171460  679.320312   \n",
       "19 2019-04-01 04:29:50.706  596.479960  556.942713  628.961346  666.293579   \n",
       "20 2019-04-01 04:59:56.131  592.760586  561.879880  634.284047  656.462280   \n",
       "21 2019-04-01 05:29:41.529  594.885325  560.940018  631.516360  652.773254   \n",
       "22 2019-04-01 05:59:47.608  598.507979  568.850671  633.502630  645.244690   \n",
       "23 2019-04-01 06:29:53.089  587.799318  550.826846  621.210245  672.942444   \n",
       "24 2019-04-01 06:59:58.484  583.993537  546.209617  616.041753  662.727661   \n",
       "25 2019-04-01 07:29:43.896  585.043183  549.774814  620.698559  692.804077   \n",
       "26 2019-04-01 07:59:49.389  580.910694  543.131498  614.097852  661.217163   \n",
       "27 2019-04-01 08:29:55.074  576.694490  544.091156  618.576555  638.817505   \n",
       "28 2019-04-01 08:59:40.980  578.712538  544.206514  615.519523  627.899048   \n",
       "29 2019-04-01 09:29:46.541  591.190101  557.477690  623.727014  701.850952   \n",
       "30 2019-04-01 09:59:52.136  590.957108  557.308957  628.634890  499.714874   \n",
       "31 2019-04-01 10:29:57.754  601.818628  566.074808  633.630846  489.762726   \n",
       "32 2019-04-01 10:59:43.186  618.773888  584.497923  656.772077  482.349274   \n",
       "33 2019-04-01 11:29:48.927  613.624088  578.848473  649.211322  493.256592   \n",
       "34 2019-04-01 11:59:54.446  612.861753  579.805967  648.747033  548.395203   \n",
       "35 2019-04-01 12:29:39.937  616.367849  581.810771  652.498241  530.254333   \n",
       "36 2019-04-01 12:59:45.495  623.472605  588.323788  658.900426  508.934387   \n",
       "37 2019-04-01 13:29:51.048  628.493011  595.131208  664.135405  566.080872   \n",
       "38 2019-04-01 13:59:56.627  636.485221  599.969225  673.920040  540.026001   \n",
       "39 2019-04-01 14:29:42.131  652.756380  619.805001  687.379448  488.786652   \n",
       "40 2019-04-01 14:59:47.764  654.879270  620.200151  693.447117  530.235413   \n",
       "41 2019-04-01 15:29:53.479  659.077679  622.895967  693.563904  504.406006   \n",
       "42 2019-04-01 15:59:59.076  663.656168  623.396055  696.697922  496.006592   \n",
       "43 2019-04-01 16:29:44.590  655.252029  618.598934  686.672549  504.519226   \n",
       "44 2019-04-01 16:59:50.167  647.014705  610.193418  682.270454  486.087738   \n",
       "45 2019-04-01 17:29:55.660  661.060433  625.393212  694.007395  557.952515   \n",
       "46 2019-04-01 17:59:41.194  689.951212  654.596936  725.059914  565.191040   \n",
       "47 2019-04-01 18:29:47.191  696.843086  659.139517  729.758704  577.450500   \n",
       "\n",
       "                    cutoff  \n",
       "0  2019-03-31 18:29:47.191  \n",
       "1  2019-03-31 18:29:47.191  \n",
       "2  2019-03-31 18:29:47.191  \n",
       "3  2019-03-31 18:29:47.191  \n",
       "4  2019-03-31 18:29:47.191  \n",
       "5  2019-03-31 18:29:47.191  \n",
       "6  2019-03-31 18:29:47.191  \n",
       "7  2019-03-31 18:29:47.191  \n",
       "8  2019-03-31 18:29:47.191  \n",
       "9  2019-03-31 18:29:47.191  \n",
       "10 2019-03-31 18:29:47.191  \n",
       "11 2019-03-31 18:29:47.191  \n",
       "12 2019-03-31 18:29:47.191  \n",
       "13 2019-03-31 18:29:47.191  \n",
       "14 2019-03-31 18:29:47.191  \n",
       "15 2019-03-31 18:29:47.191  \n",
       "16 2019-03-31 18:29:47.191  \n",
       "17 2019-03-31 18:29:47.191  \n",
       "18 2019-03-31 18:29:47.191  \n",
       "19 2019-03-31 18:29:47.191  \n",
       "20 2019-03-31 18:29:47.191  \n",
       "21 2019-03-31 18:29:47.191  \n",
       "22 2019-03-31 18:29:47.191  \n",
       "23 2019-03-31 18:29:47.191  \n",
       "24 2019-03-31 18:29:47.191  \n",
       "25 2019-03-31 18:29:47.191  \n",
       "26 2019-03-31 18:29:47.191  \n",
       "27 2019-03-31 18:29:47.191  \n",
       "28 2019-03-31 18:29:47.191  \n",
       "29 2019-03-31 18:29:47.191  \n",
       "30 2019-03-31 18:29:47.191  \n",
       "31 2019-03-31 18:29:47.191  \n",
       "32 2019-03-31 18:29:47.191  \n",
       "33 2019-03-31 18:29:47.191  \n",
       "34 2019-03-31 18:29:47.191  \n",
       "35 2019-03-31 18:29:47.191  \n",
       "36 2019-03-31 18:29:47.191  \n",
       "37 2019-03-31 18:29:47.191  \n",
       "38 2019-03-31 18:29:47.191  \n",
       "39 2019-03-31 18:29:47.191  \n",
       "40 2019-03-31 18:29:47.191  \n",
       "41 2019-03-31 18:29:47.191  \n",
       "42 2019-03-31 18:29:47.191  \n",
       "43 2019-03-31 18:29:47.191  \n",
       "44 2019-03-31 18:29:47.191  \n",
       "45 2019-03-31 18:29:47.191  \n",
       "46 2019-03-31 18:29:47.191  \n",
       "47 2019-03-31 18:29:47.191  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>daily</th>\n",
       "      <th>...</th>\n",
       "      <th>half_day</th>\n",
       "      <th>half_day_lower</th>\n",
       "      <th>half_day_upper</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-27 12:29:51.826</td>\n",
       "      <td>686.631476</td>\n",
       "      <td>562.622723</td>\n",
       "      <td>745.417673</td>\n",
       "      <td>686.631476</td>\n",
       "      <td>686.631476</td>\n",
       "      <td>-35.751178</td>\n",
       "      <td>-35.751178</td>\n",
       "      <td>-35.751178</td>\n",
       "      <td>0.585103</td>\n",
       "      <td>...</td>\n",
       "      <td>2.219219</td>\n",
       "      <td>2.219219</td>\n",
       "      <td>2.219219</td>\n",
       "      <td>-38.555500</td>\n",
       "      <td>-38.555500</td>\n",
       "      <td>-38.555500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>650.880298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-27 12:59:57.501</td>\n",
       "      <td>686.608827</td>\n",
       "      <td>566.615931</td>\n",
       "      <td>744.127184</td>\n",
       "      <td>686.608827</td>\n",
       "      <td>686.608827</td>\n",
       "      <td>-31.304333</td>\n",
       "      <td>-31.304333</td>\n",
       "      <td>-31.304333</td>\n",
       "      <td>5.106015</td>\n",
       "      <td>...</td>\n",
       "      <td>2.557442</td>\n",
       "      <td>2.557442</td>\n",
       "      <td>2.557442</td>\n",
       "      <td>-38.967790</td>\n",
       "      <td>-38.967790</td>\n",
       "      <td>-38.967790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>655.304494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-27 13:29:43.264</td>\n",
       "      <td>686.586428</td>\n",
       "      <td>577.643184</td>\n",
       "      <td>746.763532</td>\n",
       "      <td>686.586428</td>\n",
       "      <td>686.586428</td>\n",
       "      <td>-23.612711</td>\n",
       "      <td>-23.612711</td>\n",
       "      <td>-23.612711</td>\n",
       "      <td>9.528493</td>\n",
       "      <td>...</td>\n",
       "      <td>6.202177</td>\n",
       "      <td>6.202177</td>\n",
       "      <td>6.202177</td>\n",
       "      <td>-39.343381</td>\n",
       "      <td>-39.343381</td>\n",
       "      <td>-39.343381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>662.973717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27 13:59:48.941</td>\n",
       "      <td>686.563778</td>\n",
       "      <td>579.154592</td>\n",
       "      <td>749.177429</td>\n",
       "      <td>686.563778</td>\n",
       "      <td>686.563778</td>\n",
       "      <td>-22.098150</td>\n",
       "      <td>-22.098150</td>\n",
       "      <td>-22.098150</td>\n",
       "      <td>13.883380</td>\n",
       "      <td>...</td>\n",
       "      <td>3.707344</td>\n",
       "      <td>3.707344</td>\n",
       "      <td>3.707344</td>\n",
       "      <td>-39.688874</td>\n",
       "      <td>-39.688874</td>\n",
       "      <td>-39.688874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>664.465629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-27 14:29:54.668</td>\n",
       "      <td>686.541129</td>\n",
       "      <td>590.728811</td>\n",
       "      <td>762.218364</td>\n",
       "      <td>686.541129</td>\n",
       "      <td>686.541129</td>\n",
       "      <td>-10.612252</td>\n",
       "      <td>-10.612252</td>\n",
       "      <td>-10.612252</td>\n",
       "      <td>18.051488</td>\n",
       "      <td>...</td>\n",
       "      <td>11.334434</td>\n",
       "      <td>11.334434</td>\n",
       "      <td>11.334434</td>\n",
       "      <td>-39.998174</td>\n",
       "      <td>-39.998174</td>\n",
       "      <td>-39.998174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675.928876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds       trend  yhat_lower  yhat_upper  trend_lower  \\\n",
       "0 2019-01-27 12:29:51.826  686.631476  562.622723  745.417673   686.631476   \n",
       "1 2019-01-27 12:59:57.501  686.608827  566.615931  744.127184   686.608827   \n",
       "2 2019-01-27 13:29:43.264  686.586428  577.643184  746.763532   686.586428   \n",
       "3 2019-01-27 13:59:48.941  686.563778  579.154592  749.177429   686.563778   \n",
       "4 2019-01-27 14:29:54.668  686.541129  590.728811  762.218364   686.541129   \n",
       "\n",
       "   trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
       "0   686.631476      -35.751178            -35.751178            -35.751178   \n",
       "1   686.608827      -31.304333            -31.304333            -31.304333   \n",
       "2   686.586428      -23.612711            -23.612711            -23.612711   \n",
       "3   686.563778      -22.098150            -22.098150            -22.098150   \n",
       "4   686.541129      -10.612252            -10.612252            -10.612252   \n",
       "\n",
       "       daily  ...   half_day  half_day_lower  half_day_upper     weekly  \\\n",
       "0   0.585103  ...   2.219219        2.219219        2.219219 -38.555500   \n",
       "1   5.106015  ...   2.557442        2.557442        2.557442 -38.967790   \n",
       "2   9.528493  ...   6.202177        6.202177        6.202177 -39.343381   \n",
       "3  13.883380  ...   3.707344        3.707344        3.707344 -39.688874   \n",
       "4  18.051488  ...  11.334434       11.334434       11.334434 -39.998174   \n",
       "\n",
       "   weekly_lower  weekly_upper  multiplicative_terms  \\\n",
       "0    -38.555500    -38.555500                   0.0   \n",
       "1    -38.967790    -38.967790                   0.0   \n",
       "2    -39.343381    -39.343381                   0.0   \n",
       "3    -39.688874    -39.688874                   0.0   \n",
       "4    -39.998174    -39.998174                   0.0   \n",
       "\n",
       "   multiplicative_terms_lower  multiplicative_terms_upper        yhat  \n",
       "0                         0.0                         0.0  650.880298  \n",
       "1                         0.0                         0.0  655.304494  \n",
       "2                         0.0                         0.0  662.973717  \n",
       "3                         0.0                         0.0  664.465629  \n",
       "4                         0.0                         0.0  675.928876  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    635.535111\n",
       "1    623.106302\n",
       "2    622.732206\n",
       "3    625.048148\n",
       "4    623.493000\n",
       "Name: yhat, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = df_cv['yhat']\n",
    "yhat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>mdape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:30:02.941000</td>\n",
       "      <td>3493.063767</td>\n",
       "      <td>59.102147</td>\n",
       "      <td>54.191281</td>\n",
       "      <td>0.085197</td>\n",
       "      <td>0.088912</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02:59:44.424000</td>\n",
       "      <td>3258.647583</td>\n",
       "      <td>57.084565</td>\n",
       "      <td>52.426720</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02:59:48.376000</td>\n",
       "      <td>2796.718645</td>\n",
       "      <td>52.884011</td>\n",
       "      <td>49.621592</td>\n",
       "      <td>0.080294</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02:59:55.728000</td>\n",
       "      <td>2918.852963</td>\n",
       "      <td>54.026410</td>\n",
       "      <td>51.424721</td>\n",
       "      <td>0.082889</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02:59:58.879000</td>\n",
       "      <td>2817.182147</td>\n",
       "      <td>53.077134</td>\n",
       "      <td>49.530503</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03:29:44.429000</td>\n",
       "      <td>2658.437732</td>\n",
       "      <td>51.560040</td>\n",
       "      <td>46.964183</td>\n",
       "      <td>0.075623</td>\n",
       "      <td>0.080155</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03:29:50.072000</td>\n",
       "      <td>2564.538929</td>\n",
       "      <td>50.641277</td>\n",
       "      <td>46.081686</td>\n",
       "      <td>0.074104</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>03:29:53.945000</td>\n",
       "      <td>2313.233399</td>\n",
       "      <td>48.096085</td>\n",
       "      <td>44.343188</td>\n",
       "      <td>0.072406</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03:30:01.264000</td>\n",
       "      <td>2355.277172</td>\n",
       "      <td>48.531198</td>\n",
       "      <td>44.879109</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03:59:47.034000</td>\n",
       "      <td>2223.587053</td>\n",
       "      <td>47.154926</td>\n",
       "      <td>43.573071</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          horizon          mse       rmse        mae      mape     mdape  \\\n",
       "0 02:30:02.941000  3493.063767  59.102147  54.191281  0.085197  0.088912   \n",
       "1 02:59:44.424000  3258.647583  57.084565  52.426720  0.083316  0.082215   \n",
       "2 02:59:48.376000  2796.718645  52.884011  49.621592  0.080294  0.082215   \n",
       "3 02:59:55.728000  2918.852963  54.026410  51.424721  0.082889  0.082215   \n",
       "4 02:59:58.879000  2817.182147  53.077134  49.530503  0.079847  0.082215   \n",
       "5 03:29:44.429000  2658.437732  51.560040  46.964183  0.075623  0.080155   \n",
       "6 03:29:50.072000  2564.538929  50.641277  46.081686  0.074104  0.078409   \n",
       "7 03:29:53.945000  2313.233399  48.096085  44.343188  0.072406  0.078409   \n",
       "8 03:30:01.264000  2355.277172  48.531198  44.879109  0.072854  0.078409   \n",
       "9 03:59:47.034000  2223.587053  47.154926  43.573071  0.070518  0.077499   \n",
       "\n",
       "   coverage  \n",
       "0  0.952381  \n",
       "1  0.952381  \n",
       "2  1.000000  \n",
       "3  1.000000  \n",
       "4  1.000000  \n",
       "5  1.000000  \n",
       "6  1.000000  \n",
       "7  1.000000  \n",
       "8  1.000000  \n",
       "9  1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p = performance_metrics(df_cv)\n",
    "df_p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaume/opt/anaconda3/lib/python3.7/site-packages/fbprophet/plot.py:487: RuntimeWarning:\n",
      "\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b59293f3b5f4aafbdab58be72eefb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_cross_validation_metric(df_cv, metric='mape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1b: Testing while removing very high values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2: Testing different time windows of the same dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_generator(df_dev, device, 'co2', '2019-02-09', '2019-05-30', '30T', graph=1)\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. low --> toward overfit\n",
    "# model.add_seasonality(name='weekly', period=7, fourier_order=5)\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=2) # prior scale\n",
    "model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# specify the time frames. Note: current binning is 30min\n",
    "predict_n = 2*48 # in data points\n",
    "today_index = df.shape[0] - predict_n # today_index = 425 # index\n",
    "# print('Cutoff date: {:%Y-%m-%d}.'.format(df.index[today_index]))\n",
    "lookback_n = int(today_index*0.99) # 1 week 336\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 3: Add filtering function on df to set a max value and make the daily pattern easier to detect**\n",
    "idea: df['y'] >= 500 then give the value 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_generator(df_dev, device, 'co2', '2019-02-09', '2019-05-30', '30T', graph=1)\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. low --> toward overfit\n",
    "# model.add_seasonality(name='weekly', period=7, fourier_order=5)\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=2) # prior scale\n",
    "model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# specify the time frames. Note: current binning is 30min\n",
    "predict_n = 2*48 # in data points\n",
    "today_index = df.shape[0] - predict_n # today_index = 425 # index\n",
    "# print('Cutoff date: {:%Y-%m-%d}.'.format(df.index[today_index]))\n",
    "lookback_n = int(today_index*0.99) # 1 week 336\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 4: Testing different parameters of the same dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_generator(df_dev, device, 'co2', '2019-02-09', '2019-05-30', '30T', graph=1)\n",
    "# config the model\n",
    "model = Prophet(interval_width=0.6, # anomaly threshold,\n",
    "                yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=False,\n",
    "                changepoint_prior_scale=0.01) # Adjusting trend flexibility. low --> toward overfit\n",
    "# model.add_seasonality(name='weekly', period=7, fourier_order=5)\n",
    "model.add_seasonality(name='daily', period=1, fourier_order=2) # prior scale\n",
    "model.add_seasonality(name='half_day', period=0.5, fourier_order=10)\n",
    "\n",
    "# specify the time frames. Note: current binning is 30min\n",
    "predict_n = 2*48 # in data points\n",
    "today_index = df.shape[0] - predict_n # today_index = 425 # index\n",
    "# print('Cutoff date: {:%Y-%m-%d}.'.format(df.index[today_index]))\n",
    "lookback_n = int(today_index*0.99) # 1 week 336\n",
    "\n",
    "# Fit the model, flag outliers, and visualize\n",
    "assert today_index>lookback_n, 'Not enough data for prediction (lookback_n<today_index)'\n",
    "fig, forecast, model = prophet_fit(df, model, today_index, lookback_days=lookback_n, predict_days=predict_n)   \n",
    "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
    "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot only the predicted data:\n",
    "Just zoom in the graph in jupyter notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>daily</th>\n",
       "      <th>daily_lower</th>\n",
       "      <th>daily_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-15 16:59:50.808</td>\n",
       "      <td>374.544353</td>\n",
       "      <td>266.113328</td>\n",
       "      <td>415.386947</td>\n",
       "      <td>374.544353</td>\n",
       "      <td>374.544353</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>-36.205270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.339083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-15 17:29:55.700</td>\n",
       "      <td>374.584762</td>\n",
       "      <td>258.721716</td>\n",
       "      <td>411.338631</td>\n",
       "      <td>374.584762</td>\n",
       "      <td>374.584762</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>-40.305981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.278781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-15 17:59:40.521</td>\n",
       "      <td>374.624722</td>\n",
       "      <td>254.766537</td>\n",
       "      <td>409.228175</td>\n",
       "      <td>374.624722</td>\n",
       "      <td>374.624722</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>-43.334157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.290565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-15 18:29:45.515</td>\n",
       "      <td>374.665133</td>\n",
       "      <td>261.033842</td>\n",
       "      <td>402.588894</td>\n",
       "      <td>374.665133</td>\n",
       "      <td>374.665133</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>-45.360915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.304219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-15 18:59:50.578</td>\n",
       "      <td>374.705546</td>\n",
       "      <td>251.941115</td>\n",
       "      <td>394.580281</td>\n",
       "      <td>374.705546</td>\n",
       "      <td>374.705546</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>-46.342360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.363186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds       trend  yhat_lower  yhat_upper  trend_lower  \\\n",
       "0 2019-07-15 16:59:50.808  374.544353  266.113328  415.386947   374.544353   \n",
       "1 2019-07-15 17:29:55.700  374.584762  258.721716  411.338631   374.584762   \n",
       "2 2019-07-15 17:59:40.521  374.624722  254.766537  409.228175   374.624722   \n",
       "3 2019-07-15 18:29:45.515  374.665133  261.033842  402.588894   374.665133   \n",
       "4 2019-07-15 18:59:50.578  374.705546  251.941115  394.580281   374.705546   \n",
       "\n",
       "   trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
       "0   374.544353      -36.205270            -36.205270            -36.205270   \n",
       "1   374.584762      -40.305981            -40.305981            -40.305981   \n",
       "2   374.624722      -43.334157            -43.334157            -43.334157   \n",
       "3   374.665133      -45.360915            -45.360915            -45.360915   \n",
       "4   374.705546      -46.342360            -46.342360            -46.342360   \n",
       "\n",
       "       daily  daily_lower  daily_upper  multiplicative_terms  \\\n",
       "0 -36.205270   -36.205270   -36.205270                   0.0   \n",
       "1 -40.305981   -40.305981   -40.305981                   0.0   \n",
       "2 -43.334157   -43.334157   -43.334157                   0.0   \n",
       "3 -45.360915   -45.360915   -45.360915                   0.0   \n",
       "4 -46.342360   -46.342360   -46.342360                   0.0   \n",
       "\n",
       "   multiplicative_terms_lower  multiplicative_terms_upper        yhat  \n",
       "0                         0.0                         0.0  338.339083  \n",
       "1                         0.0                         0.0  334.278781  \n",
       "2                         0.0                         0.0  331.290565  \n",
       "3                         0.0                         0.0  329.304219  \n",
       "4                         0.0                         0.0  328.363186  "
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-DErjktlKrJK"
   },
   "source": [
    "### Validate the results !\n",
    "* Diagnose the pattern with time-series decomposition\n",
    "* Look at performance metrics including MSE, RMSE, MAP, MAPE (see [Prophet docs](https://facebook.github.io/prophet/docs/diagnostics.html) for details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification metrics:\n",
    "* Area Under the curve ROC\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "prophet_anomaly_detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
